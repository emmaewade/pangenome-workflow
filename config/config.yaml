---
snakefile: workflow/Snakefile
latency-wait: 60
reason: True
show-failed-logs: True
keep-going: True
printshellcmds: True
rerun-incomplete: True

###Adjust this!!######
cores : 1

##################
### Adjust this! Arguments ####
##################
## more information about assembly level and version here: https://www.ncbi.nlm.nih.gov/assembly/help/#:~:text=Genome%20representation%20-%20whether%20the%20goal%20for%20the,There%20may%20still%20be%20gaps%20in%20the%20assembly.
# -r = create R plots 
# -p = number of threads
# -e --mafft a multiFASTA alignment of core genes using MAFFT
# -i = minimum percentage identity for blastp
# -cd = percentage of isolates a gene must be in to be core
# -f = output directory
config: 
    - accortaxon='accession' #options : accession or taxonomy
    - filename='workflow/testing-files/accession.txt' # Streptococcus dysgalactiae subsp. dysgalactiae and Streptococcus agalactiae , file of accessions or file of taxons
    - outname=acc_interest #results will write into results/outname
    - roary_command='-r -p 30 -e --mafft -i 80 -cd 80 -f' #roary will run "roary {roary_command} $outdir .... "
    - only_download_complete_genomes='f' ##filter to only those whose assembly level = complete genomes, only options are t or f, case sensitive!! 
    - only_download_latest='f' #filter t only those whose version = latest, only options are t or f, case sensitive!!
##################    

##########################
### Adjust this if wanted! Cluster Submission ###
##########################
#jobname: "{rule}.{jobid}"              # Provide a custom name for the jobscript that is submitted to the cluster.
#max-jobs-per-second: 1                 #Maximal number of cluster/drmaa jobs per second, default is 10, fractions allowed.
#max-status-checks-per-second: 10       #Maximal number of job status checks per second, default is 10
#jobs: 400                              #Use at most N CPU cluster/cloud jobs in parallel.
#cluster: "mkdir -p logs/ | sbatch $(config/parseJobID.sh {dependencies}) -q cpu -p shared --output=\"logs/slurm_%x_%j.out\" --error=\"logs/slurm_%x_%j.log\" --mem={resources.mem_mb} --time={resources.runtime} --parsable "
#cluster-status: "config/status-sacct.sh" #  Use to handle timeout exception, do not forget to chmod +x
#immediate-submit: True
#rerun-incomplete: True
#notemp: True
#cluster-cancel: "scancel"

###################
### Singularity ###
###################
#must be True!
use-singularity: True

#####################
### Job and Rule Resources ###
#####################
# Define the number of threads used by rules
#set-threads:
#  - make_table=1
#  - get_interest_ftp=1
#  - download_and_convert_gbff=1
#  - run_roary=1
  
#set-resources: #adjust to make specific to rules !! make_table, get_interest_ftp, download_and_convert_gbff, run_roary
#  - make_table:mem_mb=10000
#  - make_table:runtime=00:12:00
#  - get_interest_ftp:mem_mb=1000
#  - get_interest_ftp:runtime=00:12:00
#  - get_interest_ftp:mem_mb=1000
#  - download_and_convert_gbff:runtime=00:12:00
#  - download_and_convert_gbff:mem_mb=1000
#  - run_roary:runtime=00:12:00
#  - run_roary:mem_mb=1000
# For some reasons time needs quotes to be read by snakemake
default-resources:
  - mem_mb=10000 #10000 MB = 10 GB
  - disk_mb=10000
  - runtime=1440 #720 seconds  = 12 hours, 1440 seconds = 24 hours
  - tasks=1
  - cpus_per_task=1
  - nodes=8
  




